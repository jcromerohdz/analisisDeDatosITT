{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(A|B) = P(A)P(B|A) / P(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo usarlo con ML para construír un clasificador?\n",
    "Ejemplo. Expresar la probabilidad de que un email sea Spam si contiene la palabra \"Free\".\n",
    "\n",
    "* P(SPAM|Free) = P(SPAM)P(Free|SPAM) / P(Free)\n",
    "\n",
    "* Donde el numerador representa la probabilidad de que el mensaje sea SPAM y contenga la palabra \"Free\".\n",
    "* Y el denominador es la probabilidad de que el mensaje contenga la palabra.\n",
    " \"Free\".\n",
    " Suena complicado y mucho trabajo pero:\n",
    " Scikit-learn al rescate; Esta librería contiene el método llamado CountVectorizer que permite trabajar con gran cantidad de palabras, tambien contiene el método MultinomialNB. (Naive Bayes)\n",
    " \n",
    " * Entrenando un conjunto donde se conoce que tien Spam y \"Ham\" donde \"Ham\" son los que no son Spam, esto se conoce como Aprendizaje Supervisado.\n",
    " \n",
    " Ejercicio.\n",
    " \n",
    " Train = 3000\n",
    " Target =2\n",
    " \n",
    " Train = 2500\n",
    " Target = 500\n",
    " \n",
    " Train = 2000\n",
    " Target =1000\n",
    " \n",
    " Train = 1500\n",
    " Target = 1500\n",
    " \n",
    " Train = 1000\n",
    " Target = 2000\n",
    " \n",
    " contar cuantos Spam hay en cada uno.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root, filename)\n",
    "            \n",
    "            inBody = False\n",
    "            lines = []\n",
    "            f = io.open(path, 'r', encoding = 'latin1')\n",
    "            for line in f:\n",
    "                if inBody :\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    inBody=True\n",
    "                    \n",
    "            f.close()\n",
    "            message = '\\n'.join(lines)\n",
    "            yield path, message\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message':message, 'class': classification})\n",
    "        index.append({filename})\n",
    "        \n",
    "    return DataFrame(rows, index = index)\n",
    "\n",
    "data = DataFrame({'message':[], 'class': []})\n",
    "\n",
    "data = data.append(dataFrameFromDirectory('C:\\\\Users\\\\Vanessa\\\\Documents\\\\analisis\\\\emails\\\\spam', 'spam'))\n",
    "data = data.append(dataFrameFromDirectory('C:\\\\Users\\\\Vanessa\\\\Documents\\\\analisis\\\\emails\\\\ham', 'ham'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                    class  \\\n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  spam   \n",
       "...                                                  ...   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...   ham   \n",
       "\n",
       "                                                                                              message  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  ##############################################...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  I thought you might like these:\\n\\n1) Slim Dow...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  A POWERHOUSE GIFTING PROGRAM You Don't Want To...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  Help wanted.  We are a 14 year old fortune 500...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <html>\\n\\n<head>\\n\\n<title>ReliaQuote - Save U...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  TIRED OF THE BULL OUT THERE?\\n\\nWant To Stop L...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  Dear ricardo1 ,\\n\\n\\n\\n<html>\\n\\n<body>\\n\\n<ce...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  Cellular Phone Accessories All At Below Wholes...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <table width=\"600\" border=\"20\" align=\"center\" ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <HTML><HEAD><TITLE>FREE Motorola Cell Phone wi...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <HTML><HEAD><TITLE>Lowest Rate Services</TITLE...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  \\n\\n\\n\\nWant to watch Sporting Events?--Movies...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  Help wanted.  We are a 14 year old fortune 500...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  DEAR FRIEND,I AM MRS.  SESE-SEKO WIDOW OF LATE...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  Lowest rates available for term life insurance...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  CENTRAL BANK OF NIGERIA\\n\\nFOREIGN REMITTANCE ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  --===_SecAtt_000_1fheucnqggtggp\\n\\nContent-Typ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  ------=_NextPart_000_00B2_83B03D1E.C6530E24\\n\\...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  This is a multi-part message in MIME format.\\n...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <HTML><HEAD>\\n\\n<META http-equiv=3DContent-Typ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  DEAR FRIEND,I AM MRS.  SESE-SEKO WIDOW OF LATE...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <HTML><HEAD><TITLE>MILFhunter</TITLE>\\n\\n<META...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <html>\\n\\n<head>\\n\\n</head>\\n\\n<body>\\n\\n\\n\\n<...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\spa...  <html>\\n\\n\\n\\n<head>\\n\\n<meta http-equiv=3D\"Co...  \n",
       "...                                                                                               ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  This is possible, however using SA as a block ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  \\n\\n--- Martin Adamson <martin@srv0.ems.ed.ac....  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  ----- Original Message -----\\n\\nFrom: \"Tim Cha...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  \\n\\n> Mr Tim Chapman, freelance gentleman of l...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Smith, Graham - Computing Technician wrote:\\n\\...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Geege wrote a strange story:\\n\\n>I know a guy ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  \\n\\n[Paul Moore]\\n\\n>    but let's walk before...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  On Mon, Nov 25, 2002 at 06:54:49PM +0000, Phil...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  \\n\\nI don't know how one can expect better and...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  No, you need to learn how declarations work in...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  \\n\\n    Richie> As I understand it, post-1.8x ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  \\n\\n    Paul> I suspect the best answer is to ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  The Times\\n\\n\\n\\n \\n\\n December 04, 2002 \\n\\n ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  I have to say I was surprised about Jacko dang...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Now then I recently read a novel about exactly...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  What the hell is it with these mini remote con...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  here, for your enjoyment, is a little somethin...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Sean O'Donnell wrote:\\n\\n> Doesnt answer your ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Joe McNally writes:\\n\\n\\n\\n> What the hell is ...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  http://news.bbc.co.uk/1/hi/world/europe/254182...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Hi all.\\n\\nDoes anyone know how to set up dual...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Carlos Luna wrote:\\n\\n\\n\\n>Hi all.\\n\\n>Does an...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Hi all\\n\\n\\n\\n\\n\\nI have a prob when trying to...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Tim Chapman writes:\\n\\n\\n\\n> http://news.bbc.c...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  > I had the same problem when installing Win o...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Man killed 'trying to surf' on Tube train \\n\\n...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Hi Gianni,\\n\\n\\n\\nA very good resource for thi...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Gianni Ponzi wrote:\\n\\n> I have a prob when tr...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  Neale Pickett <neale@woozle.org> writes:\\n\\n\\n...  \n",
       "{C:\\Users\\Vanessa\\Documents\\analisis\\emails\\ham...  \\n\\nHi,\\n\\n\\n\\nI think you need to give us a l...  \n",
       "\n",
       "[3000 rows x 2 columns]>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento con todos los datos\n",
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(data['message'].values)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicción con example\n",
    "examples = ['Free Viagra now!!', 'Hi Bob, how about a game of golf tomorrow']\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento con 2500 datos\n",
    "train_data = data['message'][0:2500].values\n",
    "counts = vectorizer.fit_transform(train_data)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'][0:2500].values\n",
    "\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicción con 500 datos\n",
    "example_counts = vectorizer.transform(data['message'][-500:])\n",
    "predictions = classifier.predict(example_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prueba1 = pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham    500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de ham 16.6666666667\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de ham', 100*(prueba1[0]/len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento con 2000 datos\n",
    "train_data = data['message'][0:2000].values\n",
    "counts = vectorizer.fit_transform(train_data)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'][0:2000].values\n",
    "\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba con 1000 datos\n",
    "example_counts = vectorizer.transform(data['message'][-1000:])\n",
    "predictions = classifier.predict(example_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba2 = pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de ham 32.2\n",
      "Porcentaje de Spam 1.13333333333\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de ham', 100*prueba2[0]/len(data))\n",
    "print('Porcentaje de Spam', 100*prueba2[1]/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento con 1500 datos\n",
    "train_data = data['message'][0:1500].values\n",
    "counts = vectorizer.fit_transform(train_data)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'][0:1500].values\n",
    "\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prueba con 1500 datos\n",
    "example_counts = vectorizer.transform(data['message'][-1500:])\n",
    "predictions = classifier.predict(example_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prueba3 = pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de ham 48.5333333333\n",
      "Porcentaje de Spam 1.46666666667\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de ham', 100*prueba3[0]/len(data))\n",
    "print('Porcentaje de Spam', 100*prueba3[1]/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento con 1000 datos\n",
    "train_data = data['message'][0:1000].values\n",
    "counts = vectorizer.fit_transform(train_data)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'][0:1000].values\n",
    "\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prueba con 2000 datos\n",
    "example_counts = vectorizer.transform(data['message'][-2000:])\n",
    "predictions = classifier.predict(example_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prueba4 = pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de ham 65.4\n",
      "Porcentaje de Spam 1.26666666667\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de ham', 100*prueba4[0]/len(data))\n",
    "print('Porcentaje de Spam', 100*prueba4[1]/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
